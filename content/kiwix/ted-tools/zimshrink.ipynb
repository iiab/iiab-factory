{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sought-throw",
   "metadata": {},
   "source": [
    "## Modifying ZIM Files\n",
    "\n",
    "#### The Larger Picture\n",
    "* Kiwix scrapes many useful sources, but sometimes the chunks are too big for IIAB.\n",
    "* Using the zimdump program, the highly compressed ZIM files can be flattened into a file tree, modified, and then re-packaged as a ZIM file.\n",
    "* This Notebook has a collection of tools which help in the above process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-constitutional",
   "metadata": {},
   "source": [
    "#### How to Use this notebook\n",
    "* There are install steps that only need to happen once. The cells containing these steps are set to \"Raw\" in the right most dropdown so that they do not execute automatically each time the notebook starts.\n",
    "* The following bash script successfully installed zimtools on Ubuntu 20.04.It only needs to be run once. I think it's easier to do it from the command line, with tab completion. In a terminal, do the following:\n",
    "\n",
    "```\n",
    "cd /opt/iiab/iiab-factory/content/kiwix/generic/ \n",
    "sudo ./install-zim-tools.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-gregory",
   "metadata": {},
   "source": [
    "* **Some conventions**: Jupyter does not want to run as root. We will create a file structure that exists in the users home directory -- so the application will be able to write all the files it needs to function.\n",
    "```\n",
    "<PREFIX>\n",
    "├── new-zim\n",
    "├── tree\n",
    "├── working\n",
    "└── zim-src\n",
    "```\n",
    "In general terms, this program will dump the zim data into \"tree\", modify it, gather additional data into \"working\"\n",
    ", and create a ZIM file in \"new_zim\"\n",
    "* For testing purposes, the user will need to link from the server's document root to her home directory (so that the nginx http server in IIAB will serve the candidate in \"tree):\n",
    "\n",
    "```\n",
    "cd\n",
    "mkdir -p zimtest\n",
    "ln -s /home/<user name>/zimtest /library/www/html/zimtest \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-plaintiff",
   "metadata": {},
   "source": [
    "#### Installation Notes to myself\n",
    "* Installing on Windows 10 insider preview WSL2. Used https://towardsdatascience.com/configuring-jupyter-notebook-in-windows-subsystem-linux-wsl2-c757893e9d69.\n",
    "* First tried installing miniconda, and then installing jupyterlab with it.\n",
    "* Wanted VIM bindings to edit cells, but jupyterlab version installed by conda was too old for jupyter-vim extenion. Wound up deleting old version with conda, and used pip to install both.\n",
    "* Jupyterlab seems to make the current directory its root. I created a notebook directory, and aways start jupyter lab from my home directiry\n",
    "* Discovered that I could enable writing by non-root group in the iiab-factory repo, and continue to use git for version control. Needed to make symbolic link from ~/miniconda to iiab-factory.\n",
    "* Reminder: Start jupyterlab in console via \"jupyter lab --no-browser\", and then pasteing the html link displayed into my browser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blind-wrestling",
   "metadata": {},
   "source": [
    "#### Declare input and output\n",
    "* The ZIM file names tend to be long and hard to remember. The PROJECT_NAME, initialized below, is used to create path names. All of the output of the zimdump program is placed in \\<home\\>/zimtest/\\<PROJECT_NAME\\>/tree. All if the intermediate downloads, and data, are placed in \\<home\\>/zimtest/\\<PROJECT_NAME\\>/working. If you use the IIAB Admin Console to download ZIMS, you will find them in /library/zims/content/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "funky-calculator",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os,sys\n",
    "import json\n",
    "import youtube_dl\n",
    "import pprint as pprint\n",
    "\n",
    "# Declare a short project name (ZIM files are often long strings\n",
    "#PROJECT_NAME = 'ted-kiwix'\n",
    "PROJECT_NAME = 'teded'\n",
    "PREFIX = os.environ.get('ZIM_PREFIX','/ext/zims')\n",
    "TARGET_SIZE =10000000000  #10GB\n",
    "# Input the full path of the downloaded ZIM file\n",
    "ZIM_PATH = '%s/%s/zim-src/teded_en_all_2021-01.zim'%(PREFIX,PROJECT_NAME,) \n",
    "# The rest of the paths are computed and represent the standard layout\n",
    "# Jupyter sets a working director as part of it's setup. We need it's value\n",
    "HOME = os.environ['HOME']\n",
    "WORKING_DIR = PREFIX + '/' + PROJECT_NAME + '/working'\n",
    "PROJECT_DIR = PREFIX + '/' + PROJECT_NAME + '/tree'\n",
    "OUTPUT_DIR = PREFIX + '/' + PROJECT_NAME + '/output_tree'\n",
    "SOURCE_DIR = PREFIX + '/' + PROJECT_NAME + '/zim-src'\n",
    "dir_list = ['output_tree','tree','working/video_json','zim-src']\n",
    "for f in dir_list: \n",
    "    if not os.path.isdir(PREFIX + '/' + PROJECT_NAME +'/' + f):\n",
    "       os.makedirs(PREFIX + '/' + PROJECT_NAME +'/' + f)\n",
    "\n",
    "# abort if the input file cannot be found\n",
    "if not os.path.exists(ZIM_PATH):\n",
    "    print('%s path not found. Quitting. . .'%ZIM_PATH)\n",
    "    exit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "opening-reconstruction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the PREFIX:/home/ghunt/zimtest\n"
     ]
    }
   ],
   "source": [
    "print('This is the PREFIX:%s'%PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "incident-placement",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First we need to get a current copy of the script\n",
    "dest = PREFIX\n",
    "%cp /opt/iiab/iiab-factory/content/kiwix/de-namespace.sh {dest} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "static-bristol",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ set -e\n",
      "+ '[' 2 -lt 2 ']'\n",
      "+ '[' '!' -f /home/ghunt/zimtest/teded/zim-src/teded_en_all_2021-01.zim ']'\n",
      "++ ls /home/ghunt/zimtest/teded/tree\n",
      "++ wc -l\n",
      "+ contents=6\n",
      "+ '[' 6 -ne 0 ']'\n",
      "+ echo 'The /home/ghunt/zimtest/teded/tree is not empty. Delete if you want to repeat this step.'\n",
      "The /home/ghunt/zimtest/teded/tree is not empty. Delete if you want to repeat this step.\n",
      "+ exit 0\n"
     ]
    }
   ],
   "source": [
    "# The following command will zimdump to the \"tree\" directory\n",
    "#  Despite the name, removing namespaces seems unnecessary, and more complex\n",
    "# It will return without doing anything if the \"tree' is not empty\n",
    "progname = HOME + '/zimtest/de-namespace.sh'\n",
    "!{progname} {ZIM_PATH} {PROJECT_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-somewhere",
   "metadata": {},
   "source": [
    "* The next step is a manual one that you will need to do with your browser. That is: to verify that after the namespace directories were removed, and all of the html links have been adjusted correctly. Point your browser to <hostname>/zimtest/\\<PROJECT_NAME\\>/tree.\n",
    "* If everything is working, it's time to go fetch the information about each video from youtube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "minimal-correction",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1811 skipped and 0 downloaded\n"
     ]
    }
   ],
   "source": [
    "ydl = youtube_dl.YoutubeDL()\n",
    "\n",
    "downloaded = 0\n",
    "skipped = 0\n",
    "# Create a list of youtube id's\n",
    "yt_id_list = os.listdir(PROJECT_DIR + '/I/videos/')\n",
    "for yt_id in iter(yt_id_list):\n",
    "    if os.path.exists(WORKING_DIR + '/video_json/' + yt_id + '.json'):\n",
    "        # skip over items that are already downloadd\n",
    "        skipped += 1\n",
    "        continue\n",
    "    with ydl:\n",
    "       result = ydl.extract_info(\n",
    "                'http://www.youtube.com/watch?v=%s'%yt_id,\n",
    "                download=False # We just want to extract the info\n",
    "                )\n",
    "       downloaded += 1\n",
    "\n",
    "    with open(WORKING_DIR + '/video_json/' + yt_id + '.json','w') as fp:\n",
    "        fp.write(json.dumps(result))\n",
    "    #pprint.pprint(result['upload_date'],result['view_count'])\n",
    "print('%s skipped and %s downloaded'%(skipped,downloaded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-affect",
   "metadata": {},
   "source": [
    "#### Playlist Navigation to Videos\n",
    "* On the home page there is a drop down selector which lists about 70 cateegories (or playlists).\n",
    "* The value from that drop down is used to pick an entry in \"-/assets/data.js\", which in turn specifies the playlist of yourtube ID\"s that are displayed when a selection is made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "terminal-living",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_assets_data():\n",
    "    # the file <root>/assets/data.js holds the category to video mappings\n",
    "    outstr = ''\n",
    "    data = {}\n",
    "    with open(PROJECT_DIR + '/-/assets/data.js', 'r') as fp:\n",
    "    #with open(OUTPUT_DIR + '/I/assets/data.js', 'r') as fp:\n",
    "        while True:\n",
    "            line = fp.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            if line.startswith('var'):\n",
    "                if len(outstr) > 1:\n",
    "                    # clip off the trailing semicolon\n",
    "                    outstr = outstr[:-2]\n",
    "                    try:\n",
    "                        data[cat] = json.loads(outstr)\n",
    "                    except Exception:\n",
    "                        print('Parse error: %s'%outstr[:80])\n",
    "                        exit\n",
    "                cat = line[9:-4]\n",
    "                outstr = '['\n",
    "            else:\n",
    "                outstr += line\n",
    "    return data\n",
    "\n",
    "zim_category_js = get_assets_data()\n",
    "\n",
    "def get_zim_data(yt_id):\n",
    "    rtn_dict = {}\n",
    "    for cat in zim_category_js:\n",
    "        for video in range(len(zim_category_js[cat])):\n",
    "            if zim_category_js[cat][video]['id'] == yt_id:\n",
    "                rtn_dict = zim_category_js[cat][video]\n",
    "                break\n",
    "        if len(rtn_dict) > 0: break\n",
    "    return rtn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pleased-latvia",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the_power_of_nature  7\n",
      "the_basics_of_quantum_mechanics  11\n",
      "ted_ed_loves_trees  8\n",
      "mind_matters  48\n",
      "student_voices_from_tedtalksed  3\n",
      "ecofying_cities  13\n",
      "tedyouth_talks  41\n",
      "the_artist_s_palette  20\n",
      "creative_writing_workshop_campyoutube_withme  11\n",
      "even_more_ted_ed_originals  160\n",
      "new_ted_ed_originals  948\n",
      "our_changing_climate  43\n",
      "the_writer_s_workshop  27\n",
      "can_you_solve_this_riddle  56\n",
      "ted_ed_riddles_season_3  7\n",
      "moments_of_vision  12\n",
      "hone_your_media_literacy_skills  11\n",
      "ted_ed_riddles_season_1  8\n",
      "making_the_invisible_visible  9\n",
      "visualizing_data  11\n",
      "math_in_real_life  85\n",
      "exploring_the_senses  10\n",
      "out_of_this_world  43\n",
      "government_declassified  37\n",
      "think_like_a_coder_campyoutube_withme  13\n",
      "reading_between_the_lines  55\n",
      "the_world_s_people_and_places  134\n",
      "the_works_of_william_shakespeare  9\n",
      "the_world_of_sports  12\n",
      "elections_in_the_united_states  9\n",
      "awesome_nature  128\n",
      "the_great_thanksgiving_car_ride  8\n",
      "the_wonders_of_earth  13\n",
      "humans_vs_viruses  18\n",
      "before_and_after_einstein  47\n",
      "understanding_genetics  12\n",
      "how_things_work  70\n",
      "cern_space_time_101  3\n",
      "questions_no_one_yet_knows_the_answers_to  8\n",
      "ted_ed_riddles_season_2  8\n",
      "cyber_influence_power  29\n",
      "playing_with_language  26\n",
      "inventions_that_shaped_history  48\n",
      "facing_our_ugly_history  3\n",
      "the_big_questions  30\n",
      "think_like_a_coder  11\n",
      "love_actually  6\n",
      "there_s_a_poem_for_that_season_1  12\n",
      "mysteries_of_vernacular  26\n",
      "behind_the_curtain  30\n",
      "troubleshooting_the_world  86\n",
      "national_teacher_day  19\n",
      "myths_from_around_the_world  35\n",
      "superhero_science  7\n",
      "ted_ed_professional_development  5\n",
      "discovering_the_deep  28\n",
      "more_money_more_problems  9\n",
      "well_behaved_women_seldom_make_history  37\n",
      "getting_under_our_skin  163\n",
      "math_of_the_impossible  13\n",
      "history_vs  11\n",
      "brain_discoveries  13\n",
      "more_book_recommendations_from_ted_ed  38\n",
      "more_ted_ed_originals  174\n",
      "integrated_photonics  3\n",
      "a_day_in_the_life  14\n",
      "the_way_we_think  50\n",
      "ted_ed_weekend_student_talks  26\n",
      "animation_basics  12\n",
      "you_are_what_you_eat  15\n",
      "ted_ed_riddles_season_4  9\n",
      "uploads_from_ted_ed  1763\n",
      "actions_and_reactions  48\n",
      "Number of Videos in all categories -- perhaps used more than once:4975\n"
     ]
    }
   ],
   "source": [
    "# enable this cell if you want summarize each category, and get a total of videos\n",
    "#   including those that are in more than one categofy\n",
    "tot=0\n",
    "for cat in zim_category_js:\n",
    "    tot += len(zim_category_js[cat])\n",
    "    print(cat, len(zim_category_js[cat]))\n",
    "print('Number of Videos in all categories -- perhaps used more than once:%d'%tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-phrase",
   "metadata": {},
   "source": [
    "#### The following Cell is subroutines and can be left minimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "native-bangladesh",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from pymediainfo import MediaInfo\n",
    "\n",
    "def mediainfo_dict(path):\n",
    "    try:\n",
    "        minfo = MediaInfo.parse(path)\n",
    "    except:\n",
    "        print('mediainfo_dict. file not found: %s'%path)\n",
    "        return {}\n",
    "    return minfo.to_data()\n",
    "\n",
    "def select_info(path):\n",
    "    global data\n",
    "    data = mediainfo_dict(path)\n",
    "    rtn = {}\n",
    "    for index in range(len(data['tracks'])):\n",
    "        track = data['tracks'][index]\n",
    "        if track['kind_of_stream'] == 'General':\n",
    "            rtn['file_size'] = track.get('file_size',0)\n",
    "            rtn['bit_rate'] = track.get('overall_bit_rate',0)\n",
    "            rtn['time'] = track['other_duration'][0]\n",
    "        if track['kind_of_stream'] == 'Audio':\n",
    "            rtn['a_stream'] = track.get('stream_size',0)\n",
    "            rtn['a_rate'] = track.get('maximum_bit_rate',0)\n",
    "            rtn['a_channels'] = track.get('channel_s',0)\n",
    "        if track['kind_of_stream'] == 'Video':\n",
    "            rtn['v_stream'] = track.get('stream_size',0)\n",
    "            rtn['v_format'] = track['other_format'][0]\n",
    "            rtn['v_rate'] = track.get('bit_rate',0)\n",
    "            rtn['v_frame_rate'] = track.get('frame_rate',0)\n",
    "            rtn['v_width'] = track.get('width',0)\n",
    "            rtn['v_height'] = track.get('height',0)\n",
    "    return rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "crazy-malpractice",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "class Sqlite():\n",
    "   def __init__(self, filename):\n",
    "      self.conn = sqlite3.connect(filename)\n",
    "      self.conn.row_factory = sqlite3.Row\n",
    "      self.conn.text_factory = str\n",
    "      self.c = self.conn.cursor()\n",
    "    \n",
    "   def __del__(self):\n",
    "      self.conn.commit()\n",
    "      self.c.close()\n",
    "      del self.conn\n",
    "\n",
    "def get_video_json(path):\n",
    "    with open(path,'r') as fp:\n",
    "        try:\n",
    "            jsonstr = fp.read()\n",
    "            #print(path)\n",
    "            modules = json.loads(jsonstr.strip())\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(jsonstr[:80])\n",
    "            return {}\n",
    "    return modules\n",
    "\n",
    "def video_size(yt_id):\n",
    "    return os.path.getsize(PROJECT_DIR + '/-/videos/' + yt_id + '/video.webm')\n",
    "\n",
    "def make_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def download_file(url,todir):\n",
    "    local_filename = url.split('/')[-1]\n",
    "    r = requests.get(url)\n",
    "    f = open(todir + '/' + local_filename, 'wb')\n",
    "    for chunk in r.iter_content(chunk_size=512 * 1024):\n",
    "        if chunk:\n",
    "            f.write(chunk)\n",
    "    f.close()\n",
    "    \n",
    "from datetime import datetime\n",
    "def age_in_years(upload_date):\n",
    "    uploaded_dt = datetime.strptime(upload_date,\"%Y%m%d\")\n",
    "    now_dt = datetime.now()\n",
    "    days_delta = now_dt - uploaded_dt\n",
    "    years = days_delta.days/365 + 1\n",
    "    return years"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-logan",
   "metadata": {},
   "source": [
    "#### Create a sqlite database which collects Data about each Video\n",
    "* We've already downloaded the data from YouTube for each Video. So get the items that are interesing to us. Such as size,date uploaded to youtube,view count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "retired-vegetation",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "get_video_json returned no data for 9mcuIc5O-DE\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "get_video_json returned no data for XSb-pIloOFc\n"
     ]
    }
   ],
   "source": [
    "def initialize_db():\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS video_info ('\\\n",
    "            'yt_id TEXT UNIQUE, zim_size INTEGER, view_count INTEGER, age INTEGER, '\\\n",
    "            'views_per_year INTEGER, upload_date TEXT, duration TEXT, '\\\n",
    "            'height INTEGER, width INTEGER,'\\\n",
    "            'bit_rate TEXT, format TEXT, '\\\n",
    "            'average_rating REAL,slug TEXT,title TEXT)'\n",
    "    db.c.execute(sql)\n",
    "    \n",
    "db = Sqlite(WORKING_DIR + '/zim_video_info.sqlite')\n",
    "initialize_db()\n",
    "for yt_id in iter(yt_id_list):\n",
    "     \n",
    "    # fetch data from assets/data.js\n",
    "    zim_data = get_zim_data(yt_id)\n",
    "    if len(zim_data) == 0: \n",
    "        print('get_zim_data returned no data for %s'%yt_id)\n",
    "        continue\n",
    "    slug = zim_data['slug']\n",
    "    \n",
    "    # We already have youtube data for every video, use it \n",
    "    data = get_video_json(WORKING_DIR + \"/video_json/\" + yt_id + '.json')\n",
    "    if len(data) == 0:\n",
    "        print('get_video_json returned no data for %s'%yt_id)\n",
    "        continue\n",
    "    vsize = data.get('filesize',0)\n",
    "    view_count = data['view_count']\n",
    "    upload_date = data['upload_date']\n",
    "    average_rating = data['average_rating']\n",
    "    title = data['title']\n",
    "    # calculate the views_per_year since it was uploaded\n",
    "    age = round(age_in_years(upload_date))\n",
    "    views_per_year = int(view_count / age)\n",
    "        \n",
    "    # interogate the video itself\n",
    "    filename = PROJECT_DIR + '/I/videos/' + yt_id + '/video.webm'\n",
    "    vsize = os.path.getsize(filename)\n",
    "    selected_data = select_info(filename)\n",
    "    if len(selected_data) == 0:\n",
    "        duration = \"not found\"\n",
    "        bit_rate = \"\" \n",
    "        v_format = \"\"\n",
    "    else:\n",
    "        duration = selected_data['time']\n",
    "        bit_rate = selected_data['bit_rate']\n",
    "        v_format = selected_data['v_format']\n",
    "        v_height = selected_data['v_height']\n",
    "        v_width = selected_data['v_width']\n",
    "    \n",
    "    # colums names: yt_id,zim_size,view_count,views_per_year,upload_date,duration,\n",
    "    #         bit_rate, format,average_rating,slug\n",
    "    sql = 'INSERT OR REPLACE INTO video_info VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?)'\n",
    "    db.c.execute(sql,[yt_id,vsize,view_count,round(age),views_per_year,upload_date, \\\n",
    "                      duration,v_height,v_width,bit_rate,v_format,average_rating,slug,title, ])\n",
    "db.conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "infectious-invasion",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I2apGYUX7Q0 16108773 2871418 287141 20120311 6 min 3 s 354180 VP8 4.7891874 why_can_t_we_see_evidence_of_alien_life 10\n"
     ]
    }
   ],
   "source": [
    "print(yt_id,vsize,view_count,views_per_year,upload_date, \\\n",
    "                      duration,bit_rate,v_format,average_rating,slug,round(age))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "organized-figure",
   "metadata": {
    "tags": [
     "\"output_scroll\""
    ]
   },
   "source": [
    "sqlite_db = WORKING_DIR + '/zim_video_info.sqlite'\n",
    "!sqlite3 {sqlite_db} '.headers on' 'select * from video_info limit 2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-sense",
   "metadata": {},
   "source": [
    "#### Select the cutoff using view count and total size\n",
    "* Order the videos by view count. Then select the sum line in the that has the target sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "arctic-yorkshire",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Size</th>\n",
       "      <th>Sum</th>\n",
       "      <th>Views</th>\n",
       "      <th>Views</th>\n",
       "      <th>Date</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Bit Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>can_you_solve_the_prisoner_hat_riddle_alex_gen...</td>\n",
       "      <td>6.65M</td>\n",
       "      <td>6.65M</td>\n",
       "      <td>19.6M</td>\n",
       "      <td>3.27M</td>\n",
       "      <td>20151005</td>\n",
       "      <td>4 min 34 s</td>\n",
       "      <td>203320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how_thor_got_his_hammer_scott_a_mellor</td>\n",
       "      <td>8.02M</td>\n",
       "      <td>14.7M</td>\n",
       "      <td>9.68M</td>\n",
       "      <td>3.23M</td>\n",
       "      <td>20190107</td>\n",
       "      <td>4 min 51 s</td>\n",
       "      <td>230522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>which_is_stronger_glue_or_tape_elizabeth_cox</td>\n",
       "      <td>12.6M</td>\n",
       "      <td>27.3M</td>\n",
       "      <td>10.8M</td>\n",
       "      <td>2.71M</td>\n",
       "      <td>20180430</td>\n",
       "      <td>4 min 50 s</td>\n",
       "      <td>363555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what_are_those_floaty_things_in_your_eye_micha...</td>\n",
       "      <td>6.76M</td>\n",
       "      <td>34.0M</td>\n",
       "      <td>18.6M</td>\n",
       "      <td>2.66M</td>\n",
       "      <td>20141201</td>\n",
       "      <td>4 min 4 s</td>\n",
       "      <td>231795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is_marijuana_bad_for_your_brain_anees_bahji</td>\n",
       "      <td>12.1M</td>\n",
       "      <td>46.2M</td>\n",
       "      <td>4.89M</td>\n",
       "      <td>2.45M</td>\n",
       "      <td>20191202</td>\n",
       "      <td>6 min 43 s</td>\n",
       "      <td>252501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>there_are_no_scraps_of_men_alberto_cairo</td>\n",
       "      <td>36.4M</td>\n",
       "      <td>25.8G</td>\n",
       "      <td>1.07K</td>\n",
       "      <td>121</td>\n",
       "      <td>20130815</td>\n",
       "      <td>19 min 2 s</td>\n",
       "      <td>267252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>an_unexpected_place_of_healing_ramona_pierson</td>\n",
       "      <td>33.8M</td>\n",
       "      <td>25.9G</td>\n",
       "      <td>1.01K</td>\n",
       "      <td>114</td>\n",
       "      <td>20130815</td>\n",
       "      <td>11 min 12 s</td>\n",
       "      <td>421916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>digital_humanitarianism_paul_conneally</td>\n",
       "      <td>17.6M</td>\n",
       "      <td>25.9G</td>\n",
       "      <td>0.99K</td>\n",
       "      <td>112</td>\n",
       "      <td>20130626</td>\n",
       "      <td>10 min 57 s</td>\n",
       "      <td>225048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>the_economic_case_for_preschool_timothy_bartik</td>\n",
       "      <td>31.1M</td>\n",
       "      <td>25.9G</td>\n",
       "      <td>706</td>\n",
       "      <td>78.0</td>\n",
       "      <td>20130815</td>\n",
       "      <td>15 min 48 s</td>\n",
       "      <td>275169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>let_s_crowdsource_the_world_s_goals_jamie_drum...</td>\n",
       "      <td>26.6M</td>\n",
       "      <td>25.9G</td>\n",
       "      <td>687</td>\n",
       "      <td>76.0</td>\n",
       "      <td>20130628</td>\n",
       "      <td>12 min 10 s</td>\n",
       "      <td>305476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1809 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Name   Size    Sum  Views  \\\n",
       "0     can_you_solve_the_prisoner_hat_riddle_alex_gen...  6.65M  6.65M  19.6M   \n",
       "1                how_thor_got_his_hammer_scott_a_mellor  8.02M  14.7M  9.68M   \n",
       "2          which_is_stronger_glue_or_tape_elizabeth_cox  12.6M  27.3M  10.8M   \n",
       "3     what_are_those_floaty_things_in_your_eye_micha...  6.76M  34.0M  18.6M   \n",
       "4           is_marijuana_bad_for_your_brain_anees_bahji  12.1M  46.2M  4.89M   \n",
       "...                                                 ...    ...    ...    ...   \n",
       "1804           there_are_no_scraps_of_men_alberto_cairo  36.4M  25.8G  1.07K   \n",
       "1805      an_unexpected_place_of_healing_ramona_pierson  33.8M  25.9G  1.01K   \n",
       "1806             digital_humanitarianism_paul_conneally  17.6M  25.9G  0.99K   \n",
       "1807     the_economic_case_for_preschool_timothy_bartik  31.1M  25.9G    706   \n",
       "1808  let_s_crowdsource_the_world_s_goals_jamie_drum...  26.6M  25.9G    687   \n",
       "\n",
       "      Views      Date     Duration Bit Rate  \n",
       "0     3.27M  20151005   4 min 34 s   203320  \n",
       "1     3.23M  20190107   4 min 51 s   230522  \n",
       "2     2.71M  20180430   4 min 50 s   363555  \n",
       "3     2.66M  20141201    4 min 4 s   231795  \n",
       "4     2.45M  20191202   6 min 43 s   252501  \n",
       "...     ...       ...          ...      ...  \n",
       "1804    121  20130815   19 min 2 s   267252  \n",
       "1805    114  20130815  11 min 12 s   421916  \n",
       "1806    112  20130626  10 min 57 s   225048  \n",
       "1807   78.0  20130815  15 min 48 s   275169  \n",
       "1808   76.0  20130628  12 min 10 s   305476  \n",
       "\n",
       "[1809 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display \n",
    "\n",
    "def human_readable(num):\n",
    "    # return 3 significant digits and unit specifier\n",
    "    num = float(num)\n",
    "    units = [ '','K','M','G']\n",
    "    for i in range(4):\n",
    "        if num<10.0:\n",
    "            return \"%.2f%s\"%(num,units[i])\n",
    "        if num<100.0:\n",
    "            return \"%.1f%s\"%(num,units[i])\n",
    "        if num < 1000.0:\n",
    "            return \"%.0f%s\"%(num,units[i])\n",
    "        num /= 1024.0\n",
    "\n",
    "sql = 'select slug,zim_size,views_per_year,view_count,duration,upload_date,'\\\n",
    "       'bit_rate from video_info order by views_per_year desc'\n",
    "tot_sum = 0\n",
    "db.c.execute(sql)\n",
    "rows = db.c.fetchall()\n",
    "row_list = []\n",
    "boundary_views_per_year = 0\n",
    "for row in rows:\n",
    "    tot_sum += row['zim_size']\n",
    "    row_list.append([row['slug'][:60],human_readable(row['zim_size']),\\\n",
    "                              human_readable(tot_sum),human_readable(row['view_count']),\\\n",
    "                              human_readable(row['views_per_year']),\\\n",
    "                              row['upload_date'],row['duration'],row['bit_rate']])\n",
    "    if tot_sum > TARGET_SIZE and boundary_views_per_year == 0:\n",
    "        boundary_views_per_year = row['views_per_year']\n",
    "\"\"\"\n",
    "sql = 'select slug,zim_size,views_per_year,view_count,duration,upload_date,'\\\n",
    "       'format,width,height,bit_rate from video_info order by views_per_year desc'\n",
    "db.c.execute(sql)\n",
    "rows = db.c.fetchall()\n",
    "print('%60s %6s %6s %6s %6s %8s %8s'%('Name','Size','Sum','Views','Views','Date  ','Duration'))\n",
    "print('%60s %6s %6s %6s %6s %8s %8s'%('','','','','/ yr','',''))\n",
    "for row in rows:\n",
    "    tot_sum += row['zim_size']\n",
    "    print('%60s %6s %6s %6s %6s %8s %8s'%(row['slug'][:60],human_readable(row['zim_size']),\\\n",
    "                              human_readable(tot_sum),human_readable(row['view_count']),\\\n",
    "                              human_readable(row['views_per_year']),\\\n",
    "                              row['upload_date'],row['duration']))\n",
    "\"\"\"\n",
    "#df = pd.read_sql(sql,db.conn)\n",
    "df = pd.DataFrame(row_list,columns=['Name','Size','Sum','Views','Views','Date','Duration','Bit Rate'])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "available-affairs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  {N5vJSNXPEwA:{\"creator\":\"IIAB\"}},\n",
      "  {Qytj-DbXMKQ:{\"creator\":\"IIAB\"}},\n",
      "  {HHuTrcXNxOk:{\"creator\":\"IIAB\"}},\n",
      "  {Y6e_m9iq-4Q:{\"creator\":\"IIAB\"}},\n",
      "  {Nlcr1jd_Tok:{\"creator\":\"IIAB\"}}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "sql = 'select yt_id,views_per_year from video_info order by views_per_year desc limit 5'\n",
    "db.c.execute(sql)\n",
    "rows = db.c.fetchall()\n",
    "outstr = '{\\n'\n",
    "for row in rows:\n",
    "    outstr += '  {%s:{\"creator\":\"IIAB\"}},\\n'%(row['yt_id'])\n",
    "outstr = outstr[:-2] + '\\n}'\n",
    "print(outstr)\n",
    "\n",
    "with open(HOME + '/zimtest/' + PROJECT_NAME + '/id_list.sh','w') as fp:\n",
    "    fp.write(outstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-aspect",
   "metadata": {
    "tags": []
   },
   "source": [
    "* Now determine the video ID's that we want in our new zim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "registered-newsletter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will include videos with views_per_year greater than 131166\n"
     ]
    }
   ],
   "source": [
    "print('We will include videos with views_per_year greater than %s'%boundary_views_per_year)\n",
    "wanted_ids = []\n",
    "sql = 'SELECT yt_id, title from video_info where views_per_year > ?'\n",
    "db.c.execute(sql,[boundary_views_per_year,])\n",
    "rows = db.c.fetchall()\n",
    "for row in rows:\n",
    "    wanted_ids.append(row['yt_id'])\n",
    "\n",
    "with open(HOME + '/zimtest/' + PROJECT_NAME + '/wanted_list.csv','w') as fp:\n",
    "    for row in rows:\n",
    "        fp.write('%s,%s\\n'%(row['yt_id'],row['title'],))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-national",
   "metadata": {},
   "source": [
    "* Now let's start building up the output directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-orientation",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "# copy the default top level directories (these were in the zim's \"-\" directory )\n",
    "#cpy_dirs = ['assets','cache','channels']\n",
    "cpy_dirs = ['M','-','A']\n",
    "for d in cpy_dirs:\n",
    "    shutil.rmtree(os.path.join(OUTPUT_DIR,d))\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR,d))\n",
    "    src = os.path.join(PROJECT_DIR,d)\n",
    "    dest = os.path.join(OUTPUT_DIR,d)\n",
    "    shutil.copytree(src,dest,dirs_exist_ok=True, symlinks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the videos selected by the wanted_ids list to output file\n",
    "for f in wanted_ids:\n",
    "    if not os.path.isdir(os.path.join(OUTPUT_DIR,'I/videos',f)):\n",
    "        os.makedirs(os.path.join(OUTPUT_DIR,'I/videos',f))\n",
    "    src = os.path.join(PROJECT_DIR,'I/videos',f)\n",
    "    dest = os.path.join(OUTPUT_DIR,'I/videos',f)\n",
    "    shutil.copytree(src,dest,dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-aluminum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the parts of the I directory that are not videos\n",
    "src_list = os.listdir(PROJECT_DIR + '/I/')\n",
    "for item in src_list:\n",
    "    if item.find('videos') != -1: continue\n",
    "    src = os.path.join(PROJECT_DIR,'I',item)\n",
    "    if os.path.isdir(src):\n",
    "        shutil.copytree(src,OUTPUT_DIR + '/I/' + item,dirs_exist_ok=True,)\n",
    "    else:\n",
    "        shutil.copyfile(src,OUTPUT_DIR + '/I/' + item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-landing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the meta data from the original zim \"M\" directory \n",
    "#   and create a script for zimwriterfs\n",
    "def get_file_value(path):\n",
    "    with open(path,'r') as fp:\n",
    "        \n",
    "        try:\n",
    "            return fp.read()\n",
    "        except:\n",
    "            return \"\"\n",
    "meta_file_names = []        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-consortium",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write a new mapping from categories to vides (with some removed)\n",
    "outstr = ''\n",
    "for cat in zim_category_js:\n",
    "    outstr += 'var json_%s = [\\n'%cat\n",
    "    for video in range(len(zim_category_js[cat])):\n",
    "        if zim_category_js[cat][video].get('id','') in wanted_ids:\n",
    "            outstr += json.dumps(zim_category_js[cat][video],indent=1)\n",
    "            outstr += ','\n",
    "    outstr = outstr[:-1]\n",
    "    outstr += '];\\n'\n",
    "with open(OUTPUT_DIR + '/-/assets/data.js','w') as fp:\n",
    "    fp.write(outstr)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-prototype",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-extra",
   "metadata": {},
   "outputs": [],
   "source": [
    "    playlist = 'PLs2auPpToJpb6MeiaKEIpkdSWeBVgvC_p'\n",
    "    CHANNEL = 'UCljl2cmQMgzlTkeJqJier7g'\n",
    "    API_KEY = 'AIzaSyBWvv2Hnhak_VufcnIV2Xs9NVLEtk-wzoo'\n",
    "    OAUTH_ID = '491595943392-03rgcun3j7oqu21dugeq48vds4s88e2q.apps.googleusercontent.com'\n",
    "    OAUTH_SECRET = 'MkrAaNd0NNHGM5CVufZgHq3W'\n",
    "    cmd = '''curl --request POST \\\n",
    "  'https://youtube.googleapis.com/youtube/v3/playlists?key=[%s]' \\\n",
    "  --header 'Accept: application/json' \\\n",
    "  --header 'Content-Type: application/json' \\\n",
    "  --data '{}' \\\n",
    "  --compressed\n",
    "  '''%(API_KEY,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a template for a script to run zimwriterfs\n",
    "mk_zim_cmd = \"\"\"\n",
    "zimwriterfs --language=eng\\\n",
    "            --welcome=home.html\\\n",
    "            --favicon=./favicon.jpg\\\n",
    "            --title=teded_en_med\\\n",
    "            --description=\\\"TED-Ed Videos from YouTube Channel\\\"\\\n",
    "            --creator='Youtube Channel “TED-Ed”'\\\n",
    "            --publisher=IIAB\\\n",
    "            --name=TED-Ed\\\n",
    "             %s %s.zim\"\"\"%(OUTPUT_DIR,PROJECT_NAME)\n",
    "with open(HOME + '/zimtest/' + PROJECT_NAME + '-zimwriter-cmd.sh','w') as fp:\n",
    "    fp.write(mk_zim_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-medicare",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-scoop",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Sample Python code for youtube.playlists.list\n",
    "# See instructions for running these code samples locally:\n",
    "# https://developers.google.com/explorer-help/guides/code_samples#python\n",
    "\n",
    "import os\n",
    "\n",
    "import google_auth_oauthlib.flow\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "\n",
    "scopes = [\"https://www.googleapis.com/auth/youtube.readonly\"]\n",
    "A_CHANNEL =  'UC4a-Gbdw7vOaccHmFo40b9g'\n",
    "\n",
    "def main():\n",
    "    # Disable OAuthlib's HTTPS verification when running locally.\n",
    "    # *DO NOT* leave this option enabled in production.Aj\n",
    "    os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
    "\n",
    "    api_service_name = \"youtube\"\n",
    "    api_version = \"v3\"\n",
    "    client_secrets_file =  '/home/ghunt/ghunt_google.json'\n",
    "\n",
    "    # Get credentials and create an API client\n",
    "    flow = google_auth_oauthlib.flow.InstalledAppFlow.from_client_secrets_file(\n",
    "        client_secrets_file, scopes)\n",
    "    credentials = flow.run_console()\n",
    "    youtube = googleapiclient.discovery.build(\n",
    "        api_service_name, api_version, credentials=credentials)\n",
    "\n",
    "    request = youtube.playlists().list(\n",
    "       [A_CHANNEL,] \n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    print(response)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-crawford",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-delta",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-architecture",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
